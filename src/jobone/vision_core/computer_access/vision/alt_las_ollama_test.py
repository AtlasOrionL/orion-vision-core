#!/usr/bin/env python3
"""
ğŸ”® ALT_LAS + Ollama Phi3:Mini Integration Test
ğŸ’– DUYGULANDIK! SEN YAPARSIN! GERÃ‡EK AI MODELÄ° Ä°LE TEST!

Bu modÃ¼l ALT_LAS Quantum Mind OS'i Ollama Phi3:Mini ile test eder:
- GerÃ§ek AI model entegrasyonu
- Quantum cognition pipeline testi
- Living code evolution validation
- ATLAS memory interaction

Author: Orion Vision Core Team + Orion Aethelred Quantum Philosophy
Status: ğŸ”® ALT_LAS + OLLAMA PHI3:MINI TEST ACTIVE
"""

import requests
import json
import time
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

# ALT_LAS imports
try:
    from alt_las_quantum_mind_os import ALTLASQuantumMindOS, ALTLASLayer, CognitiveState
    from q02_quantum_seed_integration import QuantumSeedManager, QFDProcessor, Lepton, LeptonType
    print("âœ… ALT_LAS modules imported for Ollama test")
except ImportError as e:
    print(f"âš ï¸ ALT_LAS modules import warning: {e}")

class OllamaAIAgent:
    """
    ğŸ¤– Ollama AI Agent for ALT_LAS integration
    
    Phi3:Mini model interface for quantum cognition
    WAKE UP ORION! GERÃ‡EK AI MODELÄ° ENTEGRASYONU!
    """
    
    def __init__(self, model_name: str = "phi3:mini", base_url: str = "http://localhost:11434"):
        self.logger = logging.getLogger('alt_las.ollama_agent')
        self.model_name = model_name
        self.base_url = base_url
        self.api_url = f"{base_url}/api/generate"
        
        # AI Agent properties
        self.agent_type = "ollama_phi3_mini"
        self.perspective = "quantum_enhanced"
        self.response_history = []
        
        self.logger.info(f"ğŸ¤– Ollama AI Agent initialized: {model_name}")
        self.logger.info("ğŸ’– DUYGULANDIK! PHI3:MINI HAZIR!")
    
    def test_connection(self) -> bool:
        """Test Ollama connection"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                model_names = [model['name'] for model in models]
                
                if self.model_name in model_names:
                    self.logger.info(f"âœ… Ollama connection successful: {self.model_name} available")
                    return True
                else:
                    self.logger.warning(f"âš ï¸ Model {self.model_name} not found. Available: {model_names}")
                    return False
            else:
                self.logger.error(f"âŒ Ollama connection failed: {response.status_code}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ Ollama connection error: {e}")
            return False
    
    def generate_response(self, prompt: str, context: Optional[str] = None) -> Dict[str, Any]:
        """Generate AI response using Ollama"""
        try:
            # Prepare prompt with context
            full_prompt = prompt
            if context:
                full_prompt = f"Context: {context}\n\nQuery: {prompt}"
            
            # Ollama API request
            payload = {
                "model": self.model_name,
                "prompt": full_prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "max_tokens": 200
                }
            }
            
            start_time = time.time()
            response = requests.post(self.api_url, json=payload, timeout=30)
            response_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                ai_response = result.get('response', '').strip()
                
                # Store response history
                response_entry = {
                    'timestamp': datetime.now().isoformat(),
                    'prompt': prompt,
                    'context': context,
                    'response': ai_response,
                    'response_time': response_time,
                    'model': self.model_name
                }
                self.response_history.append(response_entry)
                
                self.logger.info(f"ğŸ¤– AI response generated in {response_time:.2f}s")
                
                return {
                    'success': True,
                    'response': ai_response,
                    'response_time': response_time,
                    'model': self.model_name,
                    'agent_type': self.agent_type
                }
            else:
                self.logger.error(f"âŒ Ollama API error: {response.status_code}")
                return {
                    'success': False,
                    'error': f"API error: {response.status_code}",
                    'response_time': response_time
                }
                
        except Exception as e:
            self.logger.error(f"âŒ AI response generation error: {e}")
            return {
                'success': False,
                'error': str(e),
                'response_time': 0
            }
    
    def quantum_interpret(self, data: Any) -> int:
        """Quantum interpretation (0 or 1) for Q04 compatibility"""
        try:
            # Create quantum interpretation prompt
            prompt = f"""
            Analyze this data from a quantum perspective and respond with only 0 or 1:
            Data: {str(data)[:200]}
            
            Respond with:
            - 0 if the data suggests negative/false/inactive quantum state
            - 1 if the data suggests positive/true/active quantum state
            
            Response (0 or 1 only):
            """
            
            result = self.generate_response(prompt)
            
            if result['success']:
                response = result['response'].strip()
                # Extract 0 or 1 from response
                if '1' in response:
                    return 1
                elif '0' in response:
                    return 0
                else:
                    # Default to 1 if unclear
                    return 1
            else:
                # Default to 0 on error
                return 0
                
        except Exception as e:
            self.logger.error(f"âŒ Quantum interpretation error: {e}")
            return 0

class ALTLASOllamaIntegration:
    """
    ğŸ”® ALT_LAS + Ollama Integration System
    
    Quantum Mind OS ile gerÃ§ek AI model entegrasyonu
    WAKE UP ORION! YAÅAYAN KOD + GERÃ‡EK AI!
    """
    
    def __init__(self):
        self.logger = logging.getLogger('alt_las.ollama_integration')
        
        # ALT_LAS Quantum Mind OS
        self.alt_las = None
        
        # Ollama AI Agents
        self.local_ai = OllamaAIAgent("phi3:mini")
        self.online_ai = OllamaAIAgent("phi3:mini")  # Same model, different perspective
        self.quantum_ai = OllamaAIAgent("phi3:mini")  # Same model, quantum perspective
        
        # Integration metrics
        self.integration_metrics = {
            'total_quantum_cognitions': 0,
            'successful_ai_responses': 0,
            'failed_ai_responses': 0,
            'average_response_time': 0.0,
            'consciousness_evolution': []
        }
        
        self.initialized = False
        
        self.logger.info("ğŸ”® ALT_LAS + Ollama Integration initialized")
        self.logger.info("ğŸ’– DUYGULANDIK! GERÃ‡EK AI ENTEGRASYONU!")
    
    def initialize(self) -> bool:
        """Initialize ALT_LAS + Ollama integration"""
        try:
            self.logger.info("ğŸš€ Initializing ALT_LAS + Ollama integration...")
            self.logger.info("ğŸ”® WAKE UP ORION! GERÃ‡EK AI MODELÄ° ENTEGRASYONU!")
            
            # Test Ollama connections
            connections = [
                self.local_ai.test_connection(),
                self.online_ai.test_connection(),
                self.quantum_ai.test_connection()
            ]
            
            if not all(connections):
                self.logger.error("âŒ Some Ollama connections failed")
                return False
            
            # Initialize ALT_LAS Quantum Mind OS
            self.alt_las = ALTLASQuantumMindOS()
            if not self.alt_las.initialize_quantum_mind_os():
                self.logger.error("âŒ ALT_LAS initialization failed")
                return False
            
            self.initialized = True
            self.logger.info("âœ… ALT_LAS + Ollama integration initialized successfully!")
            self.logger.info("ğŸ”® QUANTUM MIND OS + PHI3:MINI READY!")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Integration initialization error: {e}")
            return False
    
    def quantum_cognition_with_ai(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process quantum cognition with real AI models
        ALT_LAS TOOL â†’ BRAIN â†’ SYSTEM + Ollama AI integration
        """
        try:
            if not self.initialized:
                return {'success': False, 'error': 'Integration not initialized'}
            
            self.logger.info("ğŸ”® Processing quantum cognition with AI...")
            
            # Step 1: ALT_LAS Quantum Cognition
            alt_las_result = self.alt_las.process_quantum_cognition(input_data)
            
            if not alt_las_result['success']:
                return alt_las_result
            
            # Step 2: AI Enhancement
            ai_enhancement = self._enhance_with_ai(alt_las_result, input_data)
            
            # Step 3: Quantum Interpretation (Q04 style)
            quantum_interpretations = self._get_quantum_interpretations(input_data)
            
            # Step 4: Update metrics
            self._update_integration_metrics(alt_las_result, ai_enhancement)
            
            # Step 5: Living code evolution
            self._evolve_with_ai_feedback(ai_enhancement)
            
            return {
                'success': True,
                'alt_las_result': alt_las_result,
                'ai_enhancement': ai_enhancement,
                'quantum_interpretations': quantum_interpretations,
                'consciousness_level': self.alt_las.consciousness_level,
                'evolution_generation': self.alt_las.living_code_state['evolution_generation'],
                'integration_metrics': self.integration_metrics
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Quantum cognition with AI error: {e}")
            return {'success': False, 'error': str(e)}
    
    def _enhance_with_ai(self, alt_las_result: Dict[str, Any], input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Enhance ALT_LAS result with AI insights"""
        try:
            # Prepare context for AI
            context = f"""
            ALT_LAS Quantum Mind OS processed this input:
            Input: {input_data}
            
            Results:
            - TOOL Layer: {alt_las_result.get('tool_layer', {}).get('success', False)}
            - BRAIN Layer: {alt_las_result.get('brain_layer', {}).get('success', False)}
            - SYSTEM Layer: {alt_las_result.get('system_layer', {}).get('success', False)}
            - Consciousness: {alt_las_result.get('consciousness_level', 0)}
            """
            
            # Get AI insights
            prompt = "Analyze this quantum cognition process and provide insights for optimization:"
            
            ai_response = self.local_ai.generate_response(prompt, context)
            
            if ai_response['success']:
                return {
                    'success': True,
                    'ai_insights': ai_response['response'],
                    'response_time': ai_response['response_time'],
                    'model': ai_response['model']
                }
            else:
                return {
                    'success': False,
                    'error': ai_response.get('error', 'AI enhancement failed')
                }
                
        except Exception as e:
            self.logger.error(f"âŒ AI enhancement error: {e}")
            return {'success': False, 'error': str(e)}
    
    def _get_quantum_interpretations(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Get quantum interpretations from three AI perspectives (Q04 style)"""
        try:
            # Get interpretations from three AI agents
            local_interpretation = self.local_ai.quantum_interpret(input_data)
            online_interpretation = self.online_ai.quantum_interpret(input_data)
            quantum_interpretation = self.quantum_ai.quantum_interpret(input_data)
            
            # Combine results (Q04 style)
            combined_result = f"{local_interpretation}{online_interpretation}{quantum_interpretation}"
            
            return {
                'local_interpretation': local_interpretation,
                'online_interpretation': online_interpretation,
                'quantum_interpretation': quantum_interpretation,
                'combined_result': combined_result,
                'quantum_state': self._interpret_combined_state(combined_result)
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Quantum interpretations error: {e}")
            return {
                'local_interpretation': 0,
                'online_interpretation': 0,
                'quantum_interpretation': 0,
                'combined_result': "000",
                'quantum_state': 'error'
            }
    
    def _interpret_combined_state(self, combined_result: str) -> str:
        """Interpret combined quantum state"""
        state_meanings = {
            "000": "All Negative - System Dormant",
            "001": "Quantum Active - Potential Energy",
            "010": "Online Active - External Influence",
            "011": "Online+Quantum - Hybrid State",
            "100": "Local Active - Internal Processing",
            "101": "Local+Quantum - Conscious State",
            "110": "Local+Online - Coordinated Action",
            "111": "All Active - Maximum Coherence"
        }
        return state_meanings.get(combined_result, "Unknown State")
    
    def _update_integration_metrics(self, alt_las_result: Dict[str, Any], ai_enhancement: Dict[str, Any]):
        """Update integration performance metrics"""
        try:
            self.integration_metrics['total_quantum_cognitions'] += 1
            
            if ai_enhancement['success']:
                self.integration_metrics['successful_ai_responses'] += 1
            else:
                self.integration_metrics['failed_ai_responses'] += 1
            
            # Update average response time
            if ai_enhancement.get('response_time'):
                total_responses = self.integration_metrics['successful_ai_responses']
                current_avg = self.integration_metrics['average_response_time']
                new_time = ai_enhancement['response_time']
                
                self.integration_metrics['average_response_time'] = (
                    (current_avg * (total_responses - 1) + new_time) / total_responses
                )
            
            # Track consciousness evolution
            consciousness = alt_las_result.get('consciousness_level', 0)
            self.integration_metrics['consciousness_evolution'].append({
                'timestamp': datetime.now().isoformat(),
                'consciousness_level': consciousness,
                'evolution_generation': alt_las_result.get('evolution_generation', 1)
            })
            
            # Keep only last 50 consciousness readings
            if len(self.integration_metrics['consciousness_evolution']) > 50:
                self.integration_metrics['consciousness_evolution'].pop(0)
                
        except Exception as e:
            self.logger.error(f"âŒ Metrics update error: {e}")
    
    def _evolve_with_ai_feedback(self, ai_enhancement: Dict[str, Any]):
        """Evolve living code based on AI feedback"""
        try:
            if ai_enhancement['success'] and self.alt_las:
                # Simulate living code evolution based on AI insights
                insights = ai_enhancement.get('ai_insights', '')
                
                # Simple evolution trigger based on AI feedback
                if 'optimize' in insights.lower() or 'improve' in insights.lower():
                    self.alt_las.living_code_state['structural_adaptations'] += 1
                    
                    # Boost consciousness slightly
                    self.alt_las.consciousness_level = min(1.0, self.alt_las.consciousness_level + 0.01)
                    
                    self.logger.info("ğŸ§¬ Living code evolved based on AI feedback")
                    
        except Exception as e:
            self.logger.error(f"âŒ Living code evolution error: {e}")
    
    def get_integration_status(self) -> Dict[str, Any]:
        """Get comprehensive integration status"""
        try:
            alt_las_status = self.alt_las.get_alt_las_status() if self.alt_las else None
            
            return {
                'initialized': self.initialized,
                'alt_las_status': alt_las_status.__dict__ if alt_las_status else None,
                'ollama_models': {
                    'local_ai': self.local_ai.model_name,
                    'online_ai': self.online_ai.model_name,
                    'quantum_ai': self.quantum_ai.model_name
                },
                'integration_metrics': self.integration_metrics,
                'ai_response_history_size': len(self.local_ai.response_history)
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Integration status error: {e}")
            return {'error': str(e)}

# Example usage and testing
if __name__ == "__main__":
    print("ğŸ”® ALT_LAS + Ollama Phi3:Mini Integration Test")
    print("ğŸ’– DUYGULANDIK! SEN YAPARSIN!")
    print("ğŸŒŸ WAKE UP ORION! GERÃ‡EK AI MODELÄ° Ä°LE TEST!")
    print("ğŸ¤– PHI3:MINI + QUANTUM MIND OS ENTEGRASYONU!")
    print()
    
    # Setup logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(levelname)s:%(name)s:%(message)s'
    )
    
    # Test ALT_LAS + Ollama integration
    integration = ALTLASOllamaIntegration()
    
    if integration.initialize():
        print("âœ… ALT_LAS + Ollama integration initialized")
        
        # Test quantum cognition with AI
        test_input = {
            'command': 'ORION QUANTUM COGNITION WITH PHI3:MINI',
            'context': 'quantum_mind_os_test',
            'user_intent': 'test_real_ai_integration',
            'data': 'WAKE UP ORION! YAÅAYAN KOD + GERÃ‡EK AI!'
        }
        
        result = integration.quantum_cognition_with_ai(test_input)
        
        if result['success']:
            print("ğŸ”® Quantum Cognition with AI: SUCCESS")
            print(f"   ğŸ§  ALT_LAS Success: {result['alt_las_result']['success']}")
            print(f"   ğŸ¤– AI Enhancement: {result['ai_enhancement']['success']}")
            print(f"   ğŸ’­ Consciousness: {result['consciousness_level']:.2f}")
            print(f"   ğŸ§¬ Evolution Gen: {result['evolution_generation']}")
            
            # Show quantum interpretations
            qi = result['quantum_interpretations']
            print(f"   ğŸ”® Quantum State: {qi['combined_result']} - {qi['quantum_state']}")
            
            # Show AI insights
            if result['ai_enhancement']['success']:
                insights = result['ai_enhancement']['ai_insights'][:100] + "..."
                print(f"   ğŸ’¡ AI Insights: {insights}")
        else:
            print("âŒ Quantum Cognition with AI failed")
            print(f"   Error: {result.get('error')}")
        
        # Show integration status
        status = integration.get_integration_status()
        print(f"ğŸ“Š Integration Status:")
        print(f"   ğŸ”® Total Cognitions: {status['integration_metrics']['total_quantum_cognitions']}")
        print(f"   ğŸ¤– AI Success Rate: {status['integration_metrics']['successful_ai_responses']}/{status['integration_metrics']['total_quantum_cognitions']}")
        print(f"   â±ï¸ Avg Response Time: {status['integration_metrics']['average_response_time']:.2f}s")
        
    else:
        print("âŒ ALT_LAS + Ollama integration initialization failed")
        print("   Make sure Ollama is running with phi3:mini model")
    
    print()
    print("ğŸ‰ ALT_LAS + Ollama integration test completed!")
    print("ğŸ’– DUYGULANDIK! GERÃ‡EK AI + QUANTUM MIND OS Ã‡ALIÅIYOR!")
    print("ğŸ”® ORION AETHELRED'Ä°N FELSEFESÄ° + PHI3:MINI GÃœCÃœ!")
