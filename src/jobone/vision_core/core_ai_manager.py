#!/usr/bin/env python3
"""
Core AI Manager - Central AI Management System
Sprint 8.1 - Atlas Prompt 8.1.2: Basic User Input (Text Chat) and AI Feedback Overlays
Orion Vision Core - Autonomous AI Operating System

This module provides centralized AI management for the Orion Vision Core
autonomous AI operating system, handling AI conversations, task management,
and internal state tracking.

Author: Orion Development Team
Version: 8.1.0
Date: 30 MayÄ±s 2025
"""

import asyncio
import logging
import threading
import time
from datetime import datetime
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, asdict
from enum import Enum
from PyQt6.QtCore import QObject, pyqtSignal, QTimer, QThread

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("CoreAIManager")

class AIState(Enum):
    """AI system state enumeration"""
    IDLE = "idle"
    THINKING = "thinking"
    PROCESSING = "processing"
    RESPONDING = "responding"
    EXECUTING = "executing"
    ERROR = "error"
    OFFLINE = "offline"

class MessageType(Enum):
    """Message type enumeration"""
    USER_INPUT = "user_input"
    AI_RESPONSE = "ai_response"
    SYSTEM_MESSAGE = "system_message"
    INTERNAL_THOUGHT = "internal_thought"
    TASK_UPDATE = "task_update"
    ERROR_MESSAGE = "error_message"

@dataclass
class AIMessage:
    """AI message data structure"""
    message_id: str
    message_type: MessageType
    content: str
    timestamp: datetime
    metadata: Dict[str, Any]
    sender: str = "ai"
    recipient: str = "user"

@dataclass
class AITask:
    """AI task data structure"""
    task_id: str
    task_name: str
    task_description: str
    task_status: str
    progress: float
    created_at: datetime
    updated_at: datetime
    metadata: Dict[str, Any]

class CoreAIManager(QObject):
    """
    Core AI management system for Orion Vision Core.
    
    Manages:
    - AI conversation state and history
    - Internal AI thoughts and processing
    - Task management and progress tracking
    - Real-time status updates
    - Integration with GUI components
    """
    
    # Signals for AI events
    message_received = pyqtSignal(dict)  # AIMessage as dict
    message_sent = pyqtSignal(dict)      # AIMessage as dict
    state_changed = pyqtSignal(str)      # AIState
    task_created = pyqtSignal(dict)      # AITask as dict
    task_updated = pyqtSignal(dict)      # AITask as dict
    internal_thought = pyqtSignal(str)   # Internal thought content
    status_update = pyqtSignal(str)      # Status message
    
    def __init__(self):
        """Initialize Core AI Manager"""
        super().__init__()
        
        # AI state
        self.current_state = AIState.OFFLINE
        self.last_state_change = datetime.now()
        
        # Message management
        self.message_history: List[AIMessage] = []
        self.message_counter = 0
        self.max_history_size = 1000
        
        # Task management
        self.active_tasks: Dict[str, AITask] = {}
        self.completed_tasks: List[AITask] = []
        self.task_counter = 0
        
        # Internal thoughts and status
        self.current_thoughts: List[str] = []
        self.current_status = "AI System Initializing..."
        self.max_thoughts = 50
        
        # AI capabilities simulation
        self.ai_capabilities = {
            'text_processing': True,
            'conversation': True,
            'task_execution': True,
            'file_operations': True,  # Now enabled
            'voice_processing': True,  # Now enabled
            'learning': True
        }

        # LLM Providers (for API compatibility)
        self.llm_providers = {
            'openai': {
                'available': True,
                'models': ['gpt-4', 'gpt-3.5-turbo'],
                'api_key': None
            },
            'anthropic': {
                'available': True,
                'models': ['claude-3-opus', 'claude-3-sonnet'],
                'api_key': None
            },
            'local': {
                'available': True,
                'models': ['orion-local'],
                'api_key': None
            }
        }
        
        # Performance metrics
        self.metrics = {
            'messages_processed': 0,
            'tasks_completed': 0,
            'uptime_seconds': 0,
            'average_response_time': 0.0,
            'error_count': 0
        }
        
        # Timers for simulation
        self.status_timer = QTimer()
        self.status_timer.timeout.connect(self._update_status)
        self.status_timer.start(2000)  # Update every 2 seconds
        
        self.thought_timer = QTimer()
        self.thought_timer.timeout.connect(self._generate_internal_thought)
        self.thought_timer.start(5000)  # Generate thought every 5 seconds
        
        # Initialize AI system
        self._initialize_ai_system()
        
        logger.info("ðŸ§  Core AI Manager initialized")

    def get_available_models(self) -> Dict[str, List[str]]:
        """Get available AI models from all providers"""
        models = {}
        for provider, config in self.llm_providers.items():
            if config['available']:
                models[provider] = config['models']
        return models

    def set_provider_api_key(self, provider: str, api_key: str) -> bool:
        """Set API key for a provider"""
        if provider in self.llm_providers:
            self.llm_providers[provider]['api_key'] = api_key
            return True
        return False

    def get_provider_status(self, provider: str) -> Dict[str, Any]:
        """Get status of a specific provider"""
        if provider in self.llm_providers:
            return self.llm_providers[provider].copy()
        return {}

    def list_providers(self) -> List[str]:
        """List all available providers"""
        return list(self.llm_providers.keys())

    def get_capabilities(self) -> Dict[str, bool]:
        """Get current AI capabilities"""
        return self.ai_capabilities.copy()

    def enable_capability(self, capability: str) -> bool:
        """Enable a specific AI capability"""
        if capability in self.ai_capabilities:
            self.ai_capabilities[capability] = True
            return True
        return False

    def disable_capability(self, capability: str) -> bool:
        """Disable a specific AI capability"""
        if capability in self.ai_capabilities:
            self.ai_capabilities[capability] = False
            return True
        return False
    
    def _initialize_ai_system(self):
        """Initialize the AI system"""
        self._change_state(AIState.IDLE)
        self._update_status("AI System Ready")
        self._add_internal_thought("Core AI Manager initialized successfully")
        
        # Add welcome message
        welcome_msg = AIMessage(
            message_id=self._generate_message_id(),
            message_type=MessageType.SYSTEM_MESSAGE,
            content="ðŸš€ Orion Vision Core AI System Online",
            timestamp=datetime.now(),
            metadata={'system': True, 'startup': True}
        )
        self._add_message(welcome_msg)
    
    def _generate_message_id(self) -> str:
        """Generate unique message ID"""
        self.message_counter += 1
        return f"msg_{self.message_counter:06d}"
    
    def _generate_task_id(self) -> str:
        """Generate unique task ID"""
        self.task_counter += 1
        return f"task_{self.task_counter:06d}"
    
    def _change_state(self, new_state: AIState):
        """Change AI state and emit signal"""
        if self.current_state != new_state:
            old_state = self.current_state
            self.current_state = new_state
            self.last_state_change = datetime.now()
            
            logger.info(f"ðŸ§  AI State changed: {old_state.value} â†’ {new_state.value}")
            self.state_changed.emit(new_state.value)
    
    def _update_status(self, status_message: str = None):
        """Update AI status periodically or with specific message"""
        if status_message:
            self.current_status = status_message
            self.status_update.emit(self.current_status)
        else:
            status_messages = [
                "Monitoring system status...",
                "Processing background tasks...",
                "Analyzing user patterns...",
                "Optimizing performance...",
                "Ready for user interaction",
                "Maintaining system health...",
                "Learning from interactions..."
            ]

            if self.current_state == AIState.IDLE:
                import random
                self.current_status = random.choice(status_messages)
                self.status_update.emit(self.current_status)
    
    def _generate_internal_thought(self):
        """Generate internal AI thoughts"""
        thoughts = [
            "Analyzing conversation patterns for better responses",
            "Optimizing task execution strategies",
            "Monitoring system performance metrics",
            "Learning from user interaction patterns",
            "Preparing for potential voice command integration",
            "Evaluating task completion efficiency",
            "Considering autonomous operation improvements",
            "Processing environmental context data"
        ]
        
        if self.current_state in [AIState.IDLE, AIState.THINKING]:
            import random
            thought = random.choice(thoughts)
            self._add_internal_thought(thought)
    
    def _add_internal_thought(self, thought: str):
        """Add internal thought and emit signal"""
        self.current_thoughts.append(f"[{datetime.now().strftime('%H:%M:%S')}] {thought}")
        
        # Limit thoughts history
        if len(self.current_thoughts) > self.max_thoughts:
            self.current_thoughts = self.current_thoughts[-self.max_thoughts:]
        
        logger.debug(f"ðŸ’­ Internal thought: {thought}")
        self.internal_thought.emit(thought)
    
    def _add_message(self, message: AIMessage):
        """Add message to history and emit signal"""
        self.message_history.append(message)
        
        # Limit message history
        if len(self.message_history) > self.max_history_size:
            self.message_history = self.message_history[-self.max_history_size:]
        
        # Update metrics
        self.metrics['messages_processed'] += 1
        
        # Emit signal
        self.message_received.emit(asdict(message))
        
        logger.info(f"ðŸ’¬ Message added: {message.message_type.value} - {message.content[:50]}...")
    
    def process_user_input(self, user_input: str) -> str:
        """
        Process user input and generate AI response.
        
        Args:
            user_input: User's text input
            
        Returns:
            AI response text
        """
        try:
            # Change state to processing
            self._change_state(AIState.THINKING)
            self._update_status("Processing user input...")
            
            # Add user message
            user_msg = AIMessage(
                message_id=self._generate_message_id(),
                message_type=MessageType.USER_INPUT,
                content=user_input,
                timestamp=datetime.now(),
                metadata={'processed': True},
                sender="user",
                recipient="ai"
            )
            self._add_message(user_msg)
            
            # Add internal thought
            self._add_internal_thought(f"Processing user input: {user_input[:30]}...")
            
            # Simulate AI processing time
            time.sleep(0.5)
            
            # Generate AI response
            self._change_state(AIState.RESPONDING)
            self._update_status("Generating response...")
            
            ai_response = self._generate_ai_response(user_input)
            
            # Add AI response message
            ai_msg = AIMessage(
                message_id=self._generate_message_id(),
                message_type=MessageType.AI_RESPONSE,
                content=ai_response,
                timestamp=datetime.now(),
                metadata={'response_to': user_msg.message_id},
                sender="ai",
                recipient="user"
            )
            self._add_message(ai_msg)
            
            # Emit sent signal
            self.message_sent.emit(asdict(ai_msg))
            
            # Return to idle state
            self._change_state(AIState.IDLE)
            self._update_status("Ready for next interaction")
            
            return ai_response
            
        except Exception as e:
            logger.error(f"âŒ Error processing user input: {e}")
            self._change_state(AIState.ERROR)
            self._update_status(f"Error: {str(e)}")
            self.metrics['error_count'] += 1
            
            return f"I apologize, but I encountered an error: {str(e)}"
    
    def _generate_ai_response(self, user_input: str) -> str:
        """Generate AI response based on user input"""
        user_input_lower = user_input.lower()
        
        # Simple response generation (will be enhanced with LLM integration in Sprint 8.2)
        if any(word in user_input_lower for word in ['hello', 'hi', 'hey']):
            return "Hello! I'm Orion, your autonomous AI assistant. How can I help you today?"
        
        elif any(word in user_input_lower for word in ['help', 'what can you do']):
            return ("I'm an autonomous AI operating system. Currently, I can:\n"
                   "â€¢ Have conversations with you\n"
                   "â€¢ Track and manage tasks\n"
                   "â€¢ Monitor system status\n"
                   "â€¢ Learn from our interactions\n\n"
                   "Soon I'll be able to manage files, execute commands, and much more!")
        
        elif any(word in user_input_lower for word in ['status', 'how are you']):
            return (f"I'm operating normally! Current status: {self.current_status}\n"
                   f"State: {self.current_state.value}\n"
                   f"Messages processed: {self.metrics['messages_processed']}\n"
                   f"Active tasks: {len(self.active_tasks)}")
        
        elif any(word in user_input_lower for word in ['task', 'create task']):
            task_name = f"User Task {self.task_counter + 1}"
            task = self.create_task(task_name, f"Task based on: {user_input}")
            return f"I've created a new task: {task_name} (ID: {task.task_id})"
        
        elif any(word in user_input_lower for word in ['thoughts', 'thinking']):
            recent_thoughts = self.current_thoughts[-3:] if self.current_thoughts else ["No recent thoughts"]
            return "Here are my recent thoughts:\n" + "\n".join(recent_thoughts)
        
        else:
            return (f"I understand you said: '{user_input}'. "
                   "I'm still learning and will have more advanced capabilities soon. "
                   "For now, try asking about my status, creating tasks, or saying hello!")
    
    def create_task(self, task_name: str, task_description: str) -> AITask:
        """Create a new AI task"""
        task = AITask(
            task_id=self._generate_task_id(),
            task_name=task_name,
            task_description=task_description,
            task_status="created",
            progress=0.0,
            created_at=datetime.now(),
            updated_at=datetime.now(),
            metadata={'created_by': 'user'}
        )
        
        self.active_tasks[task.task_id] = task
        self.task_created.emit(asdict(task))
        
        logger.info(f"ðŸ“‹ Task created: {task_name} ({task.task_id})")
        return task
    
    def update_task(self, task_id: str, status: str = None, progress: float = None):
        """Update task status and progress"""
        if task_id in self.active_tasks:
            task = self.active_tasks[task_id]
            
            if status:
                task.task_status = status
            if progress is not None:
                task.progress = progress
            
            task.updated_at = datetime.now()
            
            self.task_updated.emit(asdict(task))
            logger.info(f"ðŸ“‹ Task updated: {task_id} - {status} ({progress}%)")
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """Get conversation history as list of dictionaries"""
        return [asdict(msg) for msg in self.message_history]
    
    def get_active_tasks(self) -> List[Dict[str, Any]]:
        """Get active tasks as list of dictionaries"""
        return [asdict(task) for task in self.active_tasks.values()]
    
    def get_internal_thoughts(self) -> List[str]:
        """Get current internal thoughts"""
        return self.current_thoughts.copy()
    
    def get_ai_status(self) -> Dict[str, Any]:
        """Get comprehensive AI status"""
        return {
            'state': self.current_state.value,
            'status': self.current_status,
            'last_state_change': self.last_state_change.isoformat(),
            'capabilities': self.ai_capabilities,
            'metrics': self.metrics,
            'active_tasks_count': len(self.active_tasks),
            'message_history_count': len(self.message_history),
            'thoughts_count': len(self.current_thoughts)
        }

# Singleton instance
_core_ai_manager = None

def get_core_ai_manager() -> CoreAIManager:
    """Get the singleton Core AI Manager instance"""
    global _core_ai_manager
    if _core_ai_manager is None:
        _core_ai_manager = CoreAIManager()
    return _core_ai_manager

# Example usage and testing
if __name__ == "__main__":
    import sys
    from PyQt6.QtWidgets import QApplication
    
    app = QApplication(sys.argv)
    
    # Test Core AI Manager
    ai_manager = get_core_ai_manager()
    
    # Test conversation
    response1 = ai_manager.process_user_input("Hello!")
    print(f"AI Response: {response1}")
    
    response2 = ai_manager.process_user_input("What can you do?")
    print(f"AI Response: {response2}")
    
    response3 = ai_manager.process_user_input("Create a task")
    print(f"AI Response: {response3}")
    
    # Print status
    status = ai_manager.get_ai_status()
    print(f"\nAI Status: {status}")
    
    sys.exit(app.exec())
